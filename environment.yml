# ==============================================================================
# Conda environment for Brain-Encoders / amod-encoder
# Target: Midway3, hcn1-gpu partition, 4× L40S, CUDA 12.6
#
# Setup:
#   module load python/miniforge-25.3.0
#   conda env create -f environment.yml
#   conda activate brain-encoders
#   cd amod_encoder && pip install -e ".[gpu]" --no-deps
#
# IMPORTANT: Use miniforge, not the system anaconda.
# If miniforge isn't loaded, the old system conda (2022.05) will be used
# and package resolution will fail.
#
# If miniforge module is unavailable, you can still use the system conda —
# PyTorch is installed via pip to avoid pytorch-cuda channel issues.
# ==============================================================================
name: brain-encoders
channels:
  - conda-forge

dependencies:
  - python=3.11
  - pip

  # ── Core scientific (pinned minor versions for reproducibility) ──
  - numpy=1.26.*
  - scipy=1.14.*
  - scikit-learn=1.5.*
  - pandas=2.2.*
  - matplotlib=3.9.*
  - pillow=10.*
  - h5py=3.12.*
  - joblib=1.4.*

  # ── Neuroimaging ──
  - nibabel=5.3.*
  - nilearn=0.10.*

  # ── Stats ──
  - statsmodels=0.14.*

  # ── Config / CLI ──
  - pyyaml=6.*
  - pydantic=2.*
  - typer=0.12.*
  - rich=13.*
  - click=8.*

  # ── Performance / BLAS ──
  - mkl
  - mkl-service
  - numexpr

  # ── AWS CLI (for data downloads) ──
  - awscli

  # ── Git (for cloning CanlabCore, emonet, etc.) ──
  - git

  # ── PyTorch + everything else via pip (avoids pytorch-cuda channel issues) ──
  - pip:
    - --extra-index-url https://download.pytorch.org/whl/cu126
    - torch==2.5.1
    - torchvision==0.20.1
    - timm==1.0.12
    - osfclient
