# ==============================================================================
# Conda environment for Brain-Encoders / amod-encoder
# Target: Midway3, hcn1-gpu partition, 4× L40S, CUDA 12.6
#
# Setup:
#   module load cuda/12.6
#   module load python/miniforge-25.3.0
#   conda env create -f environment.yml
#   conda activate brain-encoders
#   cd amod_encoder && pip install -e ".[gpu]" --no-deps
#
# The --no-deps flag is important: all deps are already in conda.
# The pip install just registers the amod-encoder CLI entry point.
# ==============================================================================
name: brain-encoders
channels:
  - pytorch
  - nvidia
  - conda-forge

dependencies:
  - python=3.11

  # ── PyTorch + CUDA (pinned to known-good combo for L40S + CUDA 12.6) ──
  - pytorch::pytorch=2.5.1
  - pytorch::torchvision=0.20.1
  - pytorch::pytorch-cuda=12.6

  # ── Core scientific (pinned minor versions for reproducibility) ──
  - conda-forge::numpy=1.26.*
  - conda-forge::scipy=1.14.*
  - conda-forge::scikit-learn=1.5.*
  - conda-forge::pandas=2.2.*
  - conda-forge::matplotlib=3.9.*
  - conda-forge::pillow=10.*
  - conda-forge::h5py=3.12.*
  - conda-forge::joblib=1.4.*

  # ── Neuroimaging ──
  - conda-forge::nibabel=5.3.*
  - conda-forge::nilearn=0.10.*

  # ── Stats ──
  - conda-forge::statsmodels=0.14.*

  # ── Config / CLI ──
  - conda-forge::pyyaml=6.*
  - conda-forge::pydantic=2.9.*
  - conda-forge::typer=0.12.*
  - conda-forge::rich=13.*
  - conda-forge::click=8.*

  # ── Performance / BLAS ──
  - conda-forge::mkl
  - conda-forge::mkl-service
  - conda-forge::numexpr

  # ── AWS CLI (for data downloads) ──
  - conda-forge::awscli

  # ── Git (for cloning CanlabCore, emonet, etc.) ──
  - conda-forge::git

  # ── OSF client (for downloading from osf.io) ──
  - conda-forge::pip

  - pip:
    - osfclient
    - timm==1.0.12
