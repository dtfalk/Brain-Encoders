Metadata-Version: 2.4
Name: amod-encoder
Version: 0.1.0
Summary: ROI-agnostic reproduction of the AMOD encoding-model pipeline (Jang et al.)
Author-email: David <placeholder@example.com>
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.24
Requires-Dist: scipy>=1.10
Requires-Dist: scikit-learn>=1.3
Requires-Dist: nibabel>=5.0
Requires-Dist: nilearn>=0.10
Requires-Dist: pandas>=2.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: typer[all]>=0.9
Requires-Dist: rich>=13.0
Requires-Dist: h5py>=3.9
Requires-Dist: statsmodels>=0.14
Requires-Dist: pydantic>=2.0
Requires-Dist: matplotlib>=3.8
Requires-Dist: Pillow>=10.0
Provides-Extra: gpu
Requires-Dist: torch>=2.0; extra == "gpu"
Requires-Dist: timm>=1.0; extra == "gpu"
Provides-Extra: extractors
Requires-Dist: torch>=2.0; extra == "extractors"
Requires-Dist: timm>=1.0; extra == "extractors"
Requires-Dist: opencv-python>=4.8; extra == "extractors"
Requires-Dist: Pillow>=10.0; extra == "extractors"
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0; extra == "dev"
Requires-Dist: ruff>=0.1; extra == "dev"
Requires-Dist: mypy>=1.5; extra == "dev"
Provides-Extra: all
Requires-Dist: amod-encoder[dev,extractors,gpu]; extra == "all"

# amod_encoder — ROI-Agnostic AMOD Encoding-Model Pipeline

A Python reproduction of the **AMOD** (Amygdala MODeling) encoding-model pipeline
originally implemented in MATLAB by Jang et al.
("Understanding human amygdala function with artificial neural networks").

This project begins by rigorously replicating the original AMOD encoding framework,
rebuilding the amygdala and subregion models in a modular, ROI-agnostic Python pipeline
capable of reproducing their voxelwise and validation results. Once validated, these
encoding models are treated as functional scoring operators that predict subregional
amygdala activation for arbitrary images, allowing systematic characterization of
"amygdala space." These learned activation axes can then be integrated into a
diffusion-based image generation process to synthesize realistic images optimized for
specific subregions, moving beyond abstract activation maximization toward recognizable,
naturalistic stimuli. The generated images can be evaluated in an online behavioral study
and ultimately tested in an fMRI experiment, closing the loop from model replication to
generative synthesis to behavioral grounding and neural validation.

This package is ROI-agnostic: any brain region can be specified via a NIfTI mask
in the YAML config. The amygdala configs are provided as reference reproductions.

---

## Quick Start

```bash
# Install (CPU-only, recommended for numerical fidelity)
pip install -e ".[dev]"

# Fit encoding models for amygdala (whole ROI)
amod-encoder fit --config configs/amod_amygdala.yaml

# Evaluate (voxelwise correlation, Fisher's Z)
amod-encoder eval --config configs/amod_amygdala.yaml

# Predict IAPS/OASIS activations
amod-encoder predict-iaps-oasis --config configs/amod_amygdala.yaml

# Export betas to CSV
amod-encoder export-betas --config configs/amod_amygdala.yaml
```

---

## Data Setup

### Where to put everything

Your workspace should be organized as follows. Symlinks work fine.

```
Brain-Encoders/
├── amod_encoder/              # This Python package (you are here)
├── AMOD-main/                 # Original MATLAB scripts (reference only)
│   └── scripts/               # MATLAB .m files
│
├── data/
│   ├── ds002837/              # OpenNeuro fMRI dataset (BIDS)
│   │   └── derivatives/
│   │       ├── sub-1/func/sub-1_task-500daysofsummer_bold_blur_censor.nii.gz
│   │       ├── sub-2/func/...
│   │       └── ...sub-20/
│   ├── osf/                   # OSF data files (https://osf.io/r48gc/)
│   │   ├── 500_days_of_summer_fc7_features.mat
│   │   ├── IAPS_data_amygdala_z.csv
│   │   └── OASIS_data_amygdala_z.csv
│   └── masks/                 # ROI mask NIfTI files
│       ├── canlab2018_amygdala_combined.nii.gz
│       ├── canlab2018_CM.nii.gz
│       ├── canlab2018_SF.nii.gz
│       ├── canlab2018_AStr.nii.gz
│       └── canlab2018_LB.nii.gz
│
└── output/                    # Generated by the pipeline
    ├── amygdala/              # Whole-amygdala results
    └── subregions/            # Subregion results
```

### Step 1: Download the fMRI data

Download from OpenNeuro:
<https://openneuro.org/datasets/ds002837/versions/2.0.0>

You need the **derivatives** directory, specifically the preprocessed BOLD files:
`sub-{s}_task-500daysofsummer_bold_blur_censor.nii.gz` for subjects 1–20.

```bash
# Using the OpenNeuro CLI (recommended for large downloads):
openneuro download ds002837 data/ds002837 --include "derivatives/sub-*/func/*bold_blur_censor*"

# Or via AWS S3 (no sign-up required):
aws s3 sync --no-sign-request \
  s3://openneuro.org/ds002837 data/ds002837 \
  --exclude "*" --include "derivatives/sub-*/func/*bold_blur_censor*"
```

### Step 2: Download the OSF supplementary data

Download from OSF: <https://osf.io/r48gc/>

You need three files:
- `500_days_of_summer_fc7_features.mat` — pre-extracted EmoNet fc7 features for movie frames
- `IAPS_data_amygdala_z.csv` — IAPS validation data with z-scored predictions
- `OASIS_data_amygdala_z.csv` — OASIS validation data with z-scored predictions

Place them in `data/osf/`.

### Step 3: Get the ROI masks

The paper uses masks from the CANlab 2018 atlas for amygdala and subregions.
You need:
- **Whole amygdala**: Combined bilateral amygdala mask from canlab2018 (`canlab2018 Amy`)
- **Subregions**: CM, SF, AStr, LB masks from the same atlas

These can be obtained from the [CANlab Neuroimaging Analysis tools](https://github.com/canlab/CanlabCore).
Place them in `data/masks/` and update the `mask_path` entries in your config YAML.

### Step 4: Update config paths

Edit `configs/amod_amygdala.yaml` (or `amod_subregions.yaml`) to point to your actual data paths:

```yaml
paths:
  bids_root: /path/to/data/ds002837
  osf_fc7_mat: /path/to/data/osf/500_days_of_summer_fc7_features.mat
  output_dir: ./output/amygdala
  iaps_csv: /path/to/data/osf/IAPS_data_amygdala_z.csv
  oasis_csv: /path/to/data/osf/OASIS_data_amygdala_z.csv

roi:
  - name: amygdala
    mask_path: /path/to/data/masks/canlab2018_amygdala_combined.nii.gz
```

### Step 5: Run

```bash
pip install -e ".[dev]"
amod-encoder fit --config configs/amod_amygdala.yaml
```

---

## Reproducing AMOD Results

### Whole amygdala (develop_encoding_models_amygdala.m)

```bash
amod-encoder fit --config configs/amod_amygdala.yaml
amod-encoder eval --config configs/amod_amygdala.yaml
```

This fits PLS encoding models with 20 components, 5-fold random CV, voxelwise.
The processing order matches MATLAB: **resample → convolve → truncate**.

### Subregions (develop_encoding_models_subregions.m)

```bash
amod-encoder fit --config configs/amod_subregions.yaml
amod-encoder eval --config configs/amod_subregions.yaml
```

**Important**: The subregions MATLAB script uses a different processing order
(**convolve → truncate → resample**). This is handled automatically via the config
field `features.convolution_order: convolve_then_resample`.

### Output mapping: MATLAB → Python

| MATLAB output | Python equivalent |
|---|---|
| `sub-X_amygdala_fc7_..._output.mat` → `mean_diag_corr` | `output/artifacts/sub-XX/run-all/roi-amygdala/metrics.json` |
| `beta_sub-X_amygdala_fc7_...mat` → `b` | `output/artifacts/sub-XX/run-all/roi-amygdala/betas.npy` |
| `amygdala_..._output_matrix_atanh.mat` | `output/tables/atanh_correlation_matrix_amygdala.csv` |
| IAPS/OASIS predicted activations | `output/tables/` (via `predict-iaps-oasis`) |

### Custom ROI (any brain region)

Copy `configs/example_custom_roi.yaml`, point `roi.mask_path` to any NIfTI mask,
and run the same commands. The pipeline is identical regardless of ROI.

---

## Architecture

```
amod_encoder/
├── pyproject.toml
├── configs/                  # YAML configs driving all behavior
│   ├── amod_amygdala.yaml    # Whole amygdala replication
│   ├── amod_subregions.yaml  # CM/SF/AStr/LB subregion replication
│   └── example_custom_roi.yaml
├── src/amod_encoder/
│   ├── config.py             # Pydantic config schema + loader
│   ├── cli/                  # Typer CLI entry points (fit, eval, predict, export)
│   ├── data/                 # BIDS loading, ROI masking, timing
│   ├── stimuli/              # fc7 feature loading, alignment, HRF convolution
│   ├── models/               # PLS and Ridge encoding models
│   ├── eval/                 # CV splits, metrics, statistical tests
│   ├── predict/              # IAPS/OASIS and artificial stim prediction
│   ├── diagnostics/          # Color/spectral analysis, t-maps
│   ├── io/                   # Artifact save/load, beta export
│   └── utils/                # Logging, compute backend selection
└── tests/                    # pytest tests (no full dataset required)
```

### Key design principles

- **ROI-agnostic**: Any region is specified via config + NIfTI mask. Nothing is hardcoded to "amygdala."
- **Feature-pluggable**: EmoNet fc7 today, CLIP/DINOv2/ViT tomorrow. The encoding model only sees a (T × D) matrix.
- **Model-swappable**: PLS (paper replication) and Ridge (baseline) share the same interface. Add elastic net, reduced-rank regression, etc.
- **Config-driven**: All MATLAB hardcoded parameters live in YAML. Every run produces a config snapshot for provenance.
- **Convolution order**: The amygdala and subregion MATLAB scripts use different orders of HRF convolution vs temporal resampling. This is handled via `features.convolution_order` in config.

---

## GPU Backend

By default the CPU backend is used for numerical fidelity with MATLAB.
Set `compute.backend: torch` and `compute.device: cuda` in config for GPU
acceleration (currently supported for Ridge; PLS remains CPU-only via sklearn/SIMPLS).

---

## Key Matched Choices from MATLAB

- **Temporal alignment**: `scipy.signal.resample_poly` matching MATLAB `resample()` (polyphase FIR)
- **HRF**: SPM canonical double-gamma at dt=1s, no temporal/dispersion derivatives
- **PLS**: Custom SIMPLS implementation matching MATLAB `plsregress` internals (de Jong 1993), with sklearn `PLSRegression` (NIPALS) as fallback
- **CV**: 5-fold random (matching `crossvalind('k', N, 5)`), seeded for reproducibility
- **Metric**: Voxelwise Pearson correlation, diagonals of `corr(yhat, y_actual)`
- **Normalization**: Fisher's Z (`arctanh`, clipped at ±0.9999) on correlation matrices
- **Prediction**: `[1, features] @ betas` (intercept in row 0 of beta matrix)
- **Subregion order**: Convolve → resample (vs amygdala: resample → convolve)

---

## Running on a Slurm Cluster

Example batch script for fitting across all subjects and ROIs:

```bash
#!/bin/bash
#SBATCH --job-name=amod-fit
#SBATCH --output=amod-fit-%j.out
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=4:00:00

module load python/3.11
source venv/bin/activate

amod-encoder fit --config configs/amod_amygdala.yaml
amod-encoder fit --config configs/amod_subregions.yaml
amod-encoder eval --config configs/amod_amygdala.yaml
amod-encoder eval --config configs/amod_subregions.yaml
```

---

## License

MIT
